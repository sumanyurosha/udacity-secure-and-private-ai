#60 Days of Udacity, started on 29th June, 2019

#Day 1:
29th June, 2019
  Started Lesson 4.

#Day 2:
30th June, 2019
1. Revising the basics of ML algos. 
2. Revised lesson 3 and 4 of course. 
3. Participated in slack quiz organised by @Michael Sheinman and got 3rd position in it.

#Day 3:
1st July, 2019
1. Gave a 2-hour long technical test for Machine Learning Role and successfully cleared it.
2. Revised first 20 videos of lesson 2, Intro to PyTorch

#Day 4:
2nd July, 2019
1. Progressed further in lesson 5 and just 2 videos away from completing lesson 5.
2. Planning to complete lesson 5 by EOD tomorrow.

#Day 5:
3rd July, 2019
1. Completed Lesson 5.
2. Watched a video on Privacy by Siraj Rawal (https://youtu.be/39hNjnhY7cY)
3. Read an article on Neural Networks (https://medium.com/towards-artificial-intelligence/one-lego-at-a-time-explaining-the-math-of-how-neural-networks-learn-with-implementation-from-scratch-39144a1cf80)

#Day 6: 
4th July, 2019
Continued watching the 7th and 8th video of lesson 5. Worked on the Maths involved in the videos and cleared doubts on it by asking in the slack community.

#Day 7:
5th July, 2019
1. Continued working on later videos of lesson 5, mostly about Global Differential Privacy.
2. Watched video no. 20 to 32 in lesson 2 from Intro to PyTorch course on Udacity.

#Day 8:
6th July, 2019
1. Completed and revised lesson 5 and got better clarity about Global and Local Differential Privacy.
2. Joined study groups and expecting to attend my first virtual meetup tommorow.
3. Read an article for Getting started on Kaggle(https://towardsdatascience.com/kaggle-for-beginners-getting-started-75decb43c0c0)
4. Working on my first submission on Kaggle for Titanic problem. https://www.kaggle.com/c/titanic/overview

#Day 9:
7th July, 2019
1. Started lesson 6: Differencial Privacy for Deep Learning.
2. Read an article on analysing the Cricket World Cup 2019(https://medium.com/@arora.nishank91/analysing-cricket-world-cup-data-cd0af7cb1b11)

#Day 10:
8th July, 2019
1. Completed lesson 6 upto PATE Analysis.
2. Read the numpy documentation about all the functions used in lesson 6 from here(https://www.numpy.org/devdocs/reference/index.html)

#Day 11:
9th July, 2019
1. Advanced in lesson 6 and looking to complete it by tomorrow.
2. Working on my first problem on Kaggle, on Titanic dataset. Approaching it first by applying binary classification and will then try to design more complex approaches to increase the accuracy. In next attempt will make a neural architecture for it.

#Day 12:
10th July, 2019
1. Completed lesson 6.
2.  Done with the pre-processing of the dataset of Titanic problem. Will be trying out different models on it tomorrow.
3. Link of problem: https://www.kaggle.com/c/titanic/data

#Day 13:
11th July, 2019
1. Submitted my first problem on Kaggle and got 75% accuracy! Super excited for it. There is a lot of scope of improvement and will work on it.
2. Link to kernel(https://www.kaggle.com/sumanyurosha/kernelf82b9512ac)

#Day 14:
13th July, 2019
1. Working on PATE Analysis to understand it better.
2. Watched the video, Guest Interview: Privacy at Apple, and got to know how big players like Apple is making sense out of the customer data without impacting the privacy of their customers.
3. Formed a project group with Sourav Kumar, Labiba and Sabrina to work on Emotion Recognition project.

#Day 15:
14th July, 2019
1. Worked on lesson 6 and started working on the Project given in it. 
2. Started reading research paper as a study group activity in #sg_caffeine_coders. Link to the paper:  https://arxiv.org/pdf/1607.00133.pdf

#Day 16:
15th July, 2019
1. Revised lesson 6.
2. Attended the live webinar on Youtube and got to know how we can start contributing to the Open Source Community and how it can help us get a job.

#Day 17:
16th July, 2019
1. Revising the basics of Python from Kaggle's course (https://www.kaggle.com/learn/python).
2. Working on the basics of NLP to get started with the Emotion Detection Project for #sg_caffene_coders. 
3. Started reading some medium articles on NLP (https://medium.com/@gon.esbuyo/get-started-with-nlp-part-i-d67ca26cc828).

#Day 18:
17th July, 2019
1. Solving weekly challenge problem in #sg_applied_dl. Repo to my solution: https://github.com/sumanyurosha/kaggle/blob/master/titanic/Titanic.ipynb 
2. Read other people's kernels to understand better approaches in order to improve my model's accuracy.
3. Got to know about the importance of data visualisation, data imputation.
4. Working to organise a dataset for Emotion Recognition Project in #sg_caffeine_coders.
5. Revising the concepts of NLP.

#Day 19:
18th July, 2019
1. Exploring the datasets available on the net to get started with Emotion Recognition Project.
2. Read about NLP and it's integration with deep learning from fast.ai (https://www.fast.ai/2019/07/08/fastai-nlp/)

#Day 20:
19th July, 2019
1. Revising lesson 1 and understanding the network architectures we have used for out mini projects in the course.
2. Preparing for my deep learning interview and revisiting all the projects I have done for the same.

#Day 21:
20th July, 2019
Attended the #sg_clan zoom meetup with @Manisha @Arka @George Christopoulos @Kapadokia Titus @andreiliphd @Akshay Rajmohan @Halwai Aftab Hasan @Nikita Sukhwal @Govind @Mateusz @A S M Sadiqul Islam @Sumanyu Rosha @Venkata Rathnam Muralidharan.
Had a great time interacting with them and discussing the cool projects everyone is working on.

#Day 22:
21st July, 2019
1. Continued revising lesson 1, the training part of the lesson. 
2. Watched videos from Deep Learning playlist of youtube channel, 3Blue1Brown.(https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
3. Started to get on boarded with NLP for emotion classification project on #sg_caffeine_coders study group and saw a good video on youtube by Siraj Raval. (https://www.youtube.com/watch?v=bDxFvr1gpSU)
4. As a team of @labiba @sourav kumar and @sabrina for the above mentioned project, we have decided the dataset for emotion recognition and will start working on data exploration from the coming week.

#Day 23:
22nd July, 2019
1. I am starting revising previously completed lessons before jumping on to Fedrated Learning so that, I am totally in sync with the course content. 
2. I have revised till transfer learning part in first lesson and then will start revising differential privacy lessons.

#Day 24:
23rd July, 2019
1. Revised differential privacy from lesson 2 and 3, will start working on federated learning from tomorrow onwards.
2. Had been busy with preparation of my Deep Learning from past week, finally free to start the new lesson.
3. I also posted about the MNIST Handwritten Digit Classification mini project from lesson 1 on LinkedIn. Although it's a late post but still wanted to share my learnings with my connections over there. Link to my post: https://www.linkedin.com/feed/update/urn:li:activity:6558785182806175745

#Day25:
24th July, 2019
1. Revised lesson 6, Differential Privacy for Deep Learning and working on the Final Project given in it.
2. Reading the project work of my friend who used Deep Learning(CNN & RNN) for Fish classification.
Link to projecr report: https://github.com/kishi001/Udacity_ML_Nanodegree/blob/master/capstone/report.pdf
3. Sorted out some tutorials which will be helpful for our Emotion Classification Project for study group #sg_caffeine_coders.
4. Excited for our first team project's first virtual project, will post photos tomorrow. 

#Day 26:
25th July, 2019
1. Started working on Federated Learning and completed first 4 videos of it.
2. Read about Federated Learning from Google AI (https://ai.google/research/pubs/pub45648).
3. Aiming to complete this lesson by this weekend, so that I can start focussing more on the projects.

#Day 27:
26th July, 2019
1. Continued reading about Federated Learning on the Internet. 
2. Really fascinated by the idea of federated learning and how it helps and works. 
3. Although it will take me time to get over the Syft way of doing it but I am sure with more practice, I will be able to get it. 
4. Read the winning articles written by @sourav kumar @Lisa M. Venezia and @Shubhangi Jena in #sg_caffeine_coders. Glad to be present in that study group.

#Day 28:
27th July, 2019
1. Completed my mini porject in Federated Learning lesson.
2. Watched next 4 videos of lesson 7.
3. Reading about Recommendation Systems to employ a "frequently bought together" feature in my Organisation's website.
Will love to receive more such article/resource suggestions from all my friends in this channel.
4. Aiming to wrap up lesson 7 by this Sunday.

#Day 29:
28th July, 2019
1. Completed lesson 7 "Federated Learning".

#Day 30:
29th July, 2019
1. Made a team progress report for my team in @sg_caffeince_coders tudy group and submitted it to @shubhangi jeena
2. Started working on the Final Project for Federated Learning mentioned in the second last video of Lesson 7.

#Day 31:
30th July, 2019
1. Reading about recommendation engines to analyze how I can use deep learning to enhance their performance.
2. Completed the Final Project using MNIST dataset in lesson 7 Federated Learning.
3. Started working on lesson 8, Securing Federated Learning.

#Day 32:
31st July, 2019
1. Started working on Lesson 8 Securing Federated Learning.
2. Watched first 2 videos of it.
3. Working on the Project mentioned in 2nd video.

#Day 33:
1st August, 2019
1. Completed watching lesson 8, Securing Federated Learning.
2. Got to know about the amazing Additive Secret Sharing technique and built methods to encrypt, decrypt and add gradients.
3. Also implemented Fixed Precision Encoding technique to deal with the floating point gradients in real problems.
4. Now working on the Final Project.

#Day 34:
3rd August, 2019
1. Started working on lesson 9, Encrypted Deep Learning.
2. It is the last lesson of this course and will be very excited to finish it up :P

#Day 35:
4th August, 2019
Working on lesson 9's Encrypted Database Project.

#Day 36:
5th August, 2019
Done upto Encrypted Database Project in lesson 9, now working on the next videos.

#Day 37:
6th August, 2019
Finally completed this course! Very happy for my achievement. Although I had planned to wrap it up earlier but nothing goes as planned :P Still I am very happy that I have completed the course. Now I will fully dedicate all the coming days to my final project.
A very special thanks to all the felow mates for the encouragement and help. You guys made my learning path very interesting and enjoyable.

#Day 38:
7th August, 2019
1. Reading about word embeddings and LSTM for emotion detection project for #sg_caffeine_coders study group.
2. Saw these two videos to understand more about Embeddings. (https://www.youtube.com/watch?v=5PL0TmQhItY) (https://www.youtube.com/watch?v=186HUTBQnpY)
3. Reading about it from Pytorch's documentation: https://pytorch.org/docs/stable/nn.html#embedding
4. Reading about LSTM from Pytorch's documentation: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html
5. I am following this tutorial to get started with the initial data preprocessing steps (https://github.com/arnaudstiegler/emotion_detection/blob/master/lstm.ipynb)

#Day 39:
8th August, 2019
1. Read a tutorial to understand about word embeddings, Deep Learning with PyTorch https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html
2. Working on Emotion Recognition Project using Deep Learning and PyTroch for #sg_caffeine_coders.
3. Following the tutorials on Emotion Recognition for better direction.
4. Following some tutorials for LSTM.
  https://colah.github.io/posts/2015-08-Understanding-LSTMs/
  https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/
 
#Day 40: 
9th August, 2019
Had a office party so was not able to do much but still spared some time to read about LSTM. Working on my emotion recognition project and working on the data pre processing part. So far I have configured that we need to store the word vectors on embeddings and need to train them.

#Day 41:
10th August, 2019
1. I Had a virtual meetup with my team mates for Emotion Recognition Project for #sg_caffeine_coders.
2. We had a discussion about how to pre-pocess the data and how we can proceed with the model selection part.
3. Currently working on the data pre-processing part. 
4. Adding some more emotions to our dataset so that we can categorize them into more classes.

#Day 42:
11th August, 2019
1. Done with data preprocessing part for Emotion Recognition Project.
2. Read articles about data preprocessing for NLP 
  https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/?source=post_page-----898a84b8bd47----------------------
  https://www.kaggle.com/saxinou/nlp-01-preprocessing-data
3. Watched PyCon video for  Applied Deep Learning for NLP using PyTorch
  https://www.youtube.com/watch?v=VBM1u-UIoI0

#Day 43:
12th August, 2019
1. Started reading about RNN for the model selection purpose for my team's showcase project on Emotion Recognition.
2. One very good thing I got to know was RNNs are used wherever we want  context from previous input.
3. While RNNs give us an advantage that they have a sequential memory but they have a problem of diminishing gradient so for inputs with longer lengths we need Long Short Term Memory RNNs(LSTM) or Gated Recurrent Units(GRU).
4. Read about RNN from this article: 
  https://medium.com/mindorks/understanding-the-recurrent-neural-network-44d593f112a2
  https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9
5. Implementation of RNN from Analytics Vidya:
  https://www.analyticsvidhya.com/blog/2019/01/fundamentals-deep-learning-recurrent-neural-networks-scratch-python/
  and Andrew Trask's blog:
  https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/?source=post_page-----79e5eb8049c9----------------------
5. Reading about GRU/LSTM from here:
  https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21
  
#Day 44:
13th August, 2019
1. I read a very good article about LSTM from here: http://colah.github.io/posts/2015-08-Understanding-LSTMs/
2. I am using GRU for my model for Emotion Recognition.
3. I have trained my model on 40,000 tweets with 6 diffetent emotions.
4. I am able to get an Accuracy of 93%

  Initial epoch: 
    Epoch 1 Batch 0 Val. Loss 0.3109
    Epoch 1 Batch 100 Val. Loss 0.2826
    Epoch 1 Batch 200 Val. Loss 0.2002
    Epoch 1 Batch 300 Val. Loss 0.0954
    Epoch 1 Batch 400 Val. Loss 0.0513
    Epoch 1 Batch 500 Val. Loss 0.0687
    Epoch 1 Batch 600 Val. Loss 0.0610
    Epoch 1 Loss 0.1405 -- Train Acc. 67.0000 -- Val Acc. 90.0000
    Time taken for 1 epoch 56.8155255317688 sec

  Final epoch:
    Epoch 10 Batch 0 Val. Loss 0.0210
    Epoch 10 Batch 100 Val. Loss 0.0126
    Epoch 10 Batch 200 Val. Loss 0.0013
    Epoch 10 Batch 300 Val. Loss 0.0002
    Epoch 10 Batch 400 Val. Loss 0.0031
    Epoch 10 Batch 500 Val. Loss 0.0023
    Epoch 10 Batch 600 Val. Loss 0.0009
    Epoch 10 Loss 0.0093 -- Train Acc. 97.0000 -- Val Acc. 92.0000
    Time taken for 1 epoch 57.25882863998413 sec
    
#Day 45: 
14th August, 2019
1. Trying to play with my model for emotion recognition so that I can improve the final Validation loss.
2. Initially used GRU but now want to try with LSTM also.
3. From tomorrow will start using course contents for it also, so that we can make use of Federated Learning also.
4. Till then I am also reading Andrew Trask's blog on RNN/LSTM/GRU, he had written it back in 2015 and I am going to read it in 2019 :-P he was so ahead of time! Link to blog: https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/?source=post_page-----79e5eb8049c9----------------------

#Day 46:
15th August, 2019
1. Reading some articles for tuning my model for Emotion Recognition, here are the links:
  https://www.quora.com/How-do-I-tune-the-parameters-for-the-LSTM-RNN-using-Keras-for-time-series-modeling
  https://nanonets.com/blog/hyperparameter-optimization/
  https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html
2. Parallely working on adding Federated Learning to the project, so that we can get the extra brownie points for including course content.
Qoute: My body can be down with fever but my spirit is always up and high.

#Day 47:
16th August, 2019
1. Only one update from my side today, working on applying Federated Learning to my showcase project.

#Day 48:
17th August, 2019
1. Has been working for the whole day in resolving the environment issues related to enabling my Nvidia gpu in pysyft environment so that I can use my local system to work on deep learning with Syft. 
2. Experiments with Federated learning has been successful on other datasets so for, now it's time for adding it to the showcase project. 

#Day 49:
18th August, 2019
1. After dedicating 3 days to implement Federated Learning to Showcase Project I came to know that LSTM and RNN is not supported by Syft.
2. I have found a workaround for it and will try to implement that to it. It will be good if it works.
3. Exploring some options to hook with the Showcase Project to enhance it's applications.

#Day 50:
19th August, 2019
1. Now adding the extra flavour to our showcase project, my script is running and downloading the tweets.
2. Our model is ready now my team members are also working on it.
3. The preprocessing for live data is also done.
4. Will try to deliver the best for it.

#Day 51:
20th August, 2019
1. Preparing readme file for the project.
2. Giving the final touches to the project.

#Day52:
21st August, 2019
1. Submitted the showcase project with my team @sabrina @labiba @sourav kumar
2. Although we had submitted our project at the last moment with just few minutes remaining but we enjoyed a lot in the whole process and the experience was so wonderful and great.
3. And I have also submitted our project in #sg_caffeine_coders
4. [Link to repo](https://github.com/aksht94/UdacityOpenSource/tree/master/Federated%20Emotion%20Recogniton)

#Day53:
22nd August, 2019
1. Working on a project to extract live emotions from tweet text in real time.
2. Currently I am downloading tweets data on #brexit to collect a good amount of dataset.
3. Planning to use my emotion detection project for it.

#Day 54:
23rd August, 2019
1. Read a very informative article on Privacy Preserving Machine Learning.
2. Link to article:  https://www.google.com/url?sa=t&source=web&rct=j&url=https://arxiv.org/pdf/1804.11238&ved=2ahUKEwjV_YSp6JjkAhXYF3IKHSEyD_UQFjABegQIAhAB&usg=AOvVaw0CBHdiziAziRuDa9PRKV6S
3. This article presents about the threats AI causes and the solutions that can help us preserving our Privacy. 

#Day 55:
24th August, 2019
1. Since the scholarship phase is going to end and the showcase project is also submitted, now I revisiting all the topics covered in this course. 
2. I have started revising Differential Privacy. 
3. Continued reading this pdf document and it is very informative, link : https://www.google.com/url?sa=t&source=web&rct=j&url=https://arxiv.org/pdf/1804.11238&ved=2ahUKEwjV_YSp6JjkAhXYF3IKHSEyD_UQFjABegQIAhAB&usg=AOvVaw0CBHdiziAziRuDa9PRKV6S

#Day 56:
25th August, 2019
1. Revising the concepts of Global Differential Privacy and PATE Analysis. 
2. Watched a webinar on PATE Analysis, would like to thank @Ateniola Oluwatobi Victor for providing this webinar. It is very useful indeed. 
3. Went through the code for this explanation present at the repo provided by him at https://github.com/nerytompz/Differential-privacy-for-deeplearning-project. 

#Day 57:
26th August, 2019
1. Revising the Federated Learning from my notes. 
2. Attended today's AMA Session. 
3. Going through the projects of fellow scholars in #project-showcase-challenge chennel and find some projects to be very cool, starring their repos and planning to study the most of them since they will eventually help me learn a lot more.

#Day 58:
27th August, 2019
1. Posted about my team's showcase project in #project_showcase_challenge. Link to thread: https://secureprivataischolar.slack.com/archives/CMHLLUAE5/p1566920417094600
2. Going through the projects of fellow scholars and find some projects to be very cool, starring their repos and planning to study the most of them since they will eventually help me learn a lot more.

#Day 59:
28th August, 2019
1. Went through the projects of fellow scholars and saving their repos.
2. Went through the course content and made sure that I have completed the course.
3. Working on extending my project to integrate real time output with my model.
